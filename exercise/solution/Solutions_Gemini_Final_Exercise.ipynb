{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6JBhKxjS06v",
        "outputId": "54b0e247-2579-44bd-d784-3f1ab0e78592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr tesseract-ocr-eng\n",
            "  tesseract-ocr-osd\n",
            "0 upgraded, 6 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 8,560 kB of archives.\n",
            "After this operation, 31.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.1 [582 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 8,560 kB in 1s (8,207 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123586 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../1-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../2-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../5-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr libtesseract-dev\n",
        "!pip install -q -U google-generativeai chromadb pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4dR9Y4aMS06w"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import pathlib\n",
        "import google.generativeai as genai\n",
        "import chromadb\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KcqR5FVBS06x",
        "outputId": "6ed57029-9625-4ebd-854f-21edbed6cbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TimeoutException",
          "evalue": "Requesting secret GOOGLE_API_KEY timed out. Secrets can only be fetched when running from the Colab UI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-eef763262ef8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GOOGLE_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutException\u001b[0m: Requesting secret GOOGLE_API_KEY timed out. Secrets can only be fetched when running from the Colab UI."
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FIMOUeeS06x"
      },
      "source": [
        "# Gemini Final Exercise\n",
        "\n",
        "You're an astronomy student who's very curious about the Apollo 11 missions,\n",
        "and through your research, you've found a lot of different types of data (otherwise known as multimodal) from NASA's\n",
        "public archive.\n",
        "\n",
        "1. Text: You have the full final NASA report post-mission, spanning over 300\n",
        "pages of incredibly informative content that details a summary of everything\n",
        "that happened as well as conclusions that NASA researchers and engineers\n",
        "came to. For the sake of this exercise, we've selected 3 particularly interesting pages, and converted them to images (you'll see soon why).\n",
        "\n",
        "2. Video: You also have several clips of the famous Neil Armstrong and Buzz Aldrin footage as they\n",
        "first stepped onto the moon, containing highlights of their moonwalks as well\n",
        "as raising the American flag.\n",
        "\n",
        "3. Audio: Finally, you have highlights from the audio recorded throughout the\n",
        "mission, which provides insights into how communication between the astronauts\n",
        "occurred as well as from the astronauts to mission control.\n",
        "\n",
        "Now, you want to search through and summarize this information for your\n",
        "upcoming research paper. Using your newfound skills from this course, you\n",
        "can accomplish this using Gemini! In particular, we will build a Retrieval Augmented Generation (RAG) system that you can directly interact with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss-k463PS06y"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "Before we begin, ensure that you've uploaded the resources.zip folder and unzipped it using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O resources.zip \"https://video.udacity-data.com/topher/2024/June/66744e79_resources/resources.zip\""
      ],
      "metadata": {
        "id": "3zgeujn1nlLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip resources.zip"
      ],
      "metadata": {
        "id": "A83ccgkRvz8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As we saw throughout this course, when working with different types of data,\n",
        "we first need to parse it in a way that Gemini can understand. We will prepare our data by extracting all file names from the `resources` directory."
      ],
      "metadata": {
        "id": "TchHEWKNysN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2pWcb50S06y"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"resources/\")\n",
        "all_file_names = [str(file) for file in data_dir.rglob(\"*\") if file.is_file() and not file.name.startswith('.')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQAB2FYuHMs"
      },
      "outputs": [],
      "source": [
        "for file_name in all_file_names:\n",
        "    print(file_name)\n",
        "\n",
        "print(len(all_file_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should expect to see 14 files."
      ],
      "metadata": {
        "id": "Q-jKE-_mzBdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval Augmented Generation (RAG)\n",
        "\n",
        "To showcase how we build a RAG, we will first build one for the Text case, and generalize it further after. Here is the general idea:\n",
        "1. **Data Preparation** (done above): We first collected various types of data from NASA's public archive related to the Apollo 11 mission, including text, video, and audio files.\n",
        "2. **Data Extraction and Summarization**: Extract the multimodal data from images, e.g. extract text from images using Optical Character Recognition (OCR), and use Gemini to generate summaries using a specialized prompt.\n",
        "3. **Embedding Generation**: Convert the generated summaries into vector embeddings using Gemini's Text Embedding Model. These embeddings represent the summaries in a numerical format suitable for efficient similarity searches.\n",
        "4. **Creating a Vector Database**: A Vector database was created to store the embeddings. This database facilitates fast and efficient retrieval of relevant documents based on similarity searches. We chose to use Chroma DB.\n",
        "5. **Querying the RAG System**: For a given query, the system retrieves the most relevant documents (based on their embeddings) and generates a response using the retrieved documents as context.\n",
        "\n",
        "Something important to note is that RAGs are usually used only when there is a surplus of data. In other words, if the data can't fit into the model prompt. In this case, the data we provided likely can fit into Gemini's 1 million token window, but for the sake of simplicity and restrictions of Google Colab's runtime, we opted to use a smaller set of data."
      ],
      "metadata": {
        "id": "9tss_lYN2irS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tPe__sZS06z"
      },
      "source": [
        "### Text\n",
        "\n",
        "We will use Tesseract OCR (Optical Character Recognition) to extract text from images of the NASA report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cABpEnIAS06z"
      },
      "outputs": [],
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = (r'/usr/bin/tesseract')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function to take in our images of a PDF, transcribe them into text, and summarize each of them."
      ],
      "metadata": {
        "id": "_qLI7NRf0W6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text_summary():\n",
        "  path = pathlib.Path(\"resources/text\")\n",
        "\n",
        "  text_summary_prompt = f\"\"\"You are an assistant tailored for summarizing text for retrieval.\n",
        "  These summaries will be turned into vector embeddings and used to retrieve the raw text.\n",
        "  Give a concise summary of the text that is well optimized for retrieval. Here is the text.\"\"\"\n",
        "\n",
        "  images = []\n",
        "  text_summaries = []\n",
        "\n",
        "  for f in path.glob(\"*\"):\n",
        "    if f.is_dir() or f.name.startswith('.'):\n",
        "      continue\n",
        "\n",
        "    image = Image.open(f)\n",
        "    response = model.generate_content([text_summary_prompt, pytesseract.image_to_string(image)])\n",
        "\n",
        "    images.append(image)\n",
        "    text_summaries.append(response.text)\n",
        "\n",
        "  return images, text_summaries"
      ],
      "metadata": {
        "id": "PmhJmL6tzYGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVWPg6ohVO4B"
      },
      "outputs": [],
      "source": [
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel('models/gemini-1.5-flash', safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_files, text_summaries = create_text_summary()"
      ],
      "metadata": {
        "id": "_LDD1OYD3tzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can check out the generated summaries of the three pages we have!"
      ],
      "metadata": {
        "id": "Q4vYQfaP4VaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text_summary in text_summaries:\n",
        "  print(text_summary)"
      ],
      "metadata": {
        "id": "YOaFPyZh4NJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the Chroma database using the generated summaries. You might be wondering what Vector DB and Chroma DB are.\n",
        "\n",
        "**Vector Database**: A specialized database designed to store and manage high-dimensional vectors, which are numerical representations of data points. It allows efficient similarity searches to find vectors (and their corresponding data) that are close to a given query vector.\n",
        "\n",
        "**Chroma DB**: An implementation of a vector database used to store and retrieve vector embeddings. These embeddings are generated from our summaries and allow us to perform efficient similarity searches.\n"
      ],
      "metadata": {
        "id": "gJplIeEf4dv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmyZVoVFWH4R"
      },
      "outputs": [],
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "  def __call__(self, input: Documents) -> Embeddings:\n",
        "    model = 'models/text-embedding-004'\n",
        "    title = \"Custom query\"\n",
        "    return genai.embed_content(model=model,\n",
        "                                content=input,\n",
        "                                task_type=\"retrieval_document\",\n",
        "                                title=title)[\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hinj0EPkWJAZ"
      },
      "outputs": [],
      "source": [
        "def create_chroma_db(documents, name):\n",
        "  chroma_client = chromadb.Client()\n",
        "  db = chroma_client.get_or_create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "  for i, d in enumerate(documents):\n",
        "    db.add(\n",
        "      documents=d,\n",
        "      ids=str(i)\n",
        "    )\n",
        "  return db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_db = create_chroma_db(text_summaries, \"text_nasa\")"
      ],
      "metadata": {
        "id": "MhwanL5X3scA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also take a peak at the `text_db` and ensure that embeddings were generated:"
      ],
      "metadata": {
        "id": "pvXSb0gd5JRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'embeddings': text_db.peek()['embeddings'],\n",
        "    'documents': text_db.peek()['documents']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame.from_dict(data, orient='index').transpose()\n",
        "df"
      ],
      "metadata": {
        "id": "VgZqcKOy5ICs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see a column called `embeddings` with what are seemingly random values, but these values are actually high-dimensional vectors that represent the semantic meaning of your summaries."
      ],
      "metadata": {
        "id": "grqxGxZL5NhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's actually try querying our information. We'll test a simple example like getting some file that has to do with the Apollo 11 Flight Plan."
      ],
      "metadata": {
        "id": "NFtUbwH255EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_files(query, db):\n",
        "  results = db.query(query_texts=[query], n_results=3)\n",
        "  return results[\"ids\"][0]"
      ],
      "metadata": {
        "id": "Tv_AaE-b5iHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_relevant_files(\"Apollo 11 Flight Plan\", text_db)\n",
        "print(files)"
      ],
      "metadata": {
        "id": "SusGynR_6PRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should expect to see something like `['1', '0', '2']`. This means that the first entry in the `text_db` is most similar. If you look above at our `pd.DataFrame` output, the document with id 1 is the document about the Apollo 11 Flight Plan, so this is working as we expected!"
      ],
      "metadata": {
        "id": "qP0aOcL666DQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video and Audio\n",
        "\n",
        "Congrats! You've successfully built a working RAG for text. Now, let's extend this concept to Video and Audio, and build out some more complex queries. We'll begin by generalizing the above summary creation function to all sorts of modalities."
      ],
      "metadata": {
        "id": "roy1qlV57T6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WcSfaRubQsE"
      },
      "outputs": [],
      "source": [
        "def create_summary(modality):\n",
        "  path = data_dir / modality\n",
        "\n",
        "  summary_prompt = f\"\"\"You are an assistant tailored for summarizing {modality} for retrieval.\n",
        "  These summaries will be turned into vector embeddings and used to retrieve the raw {modality}.\n",
        "  Give a concise summary of the {modality} that is well optimized for retrieval. Here is the {modality}.\"\"\"\n",
        "\n",
        "  files = []\n",
        "  summaries = []\n",
        "\n",
        "  for f in path.glob(\"*\"):\n",
        "    if f.is_dir() or f.name.startswith('.'):\n",
        "      continue\n",
        "    print(f)\n",
        "\n",
        "    if modality == \"text\":\n",
        "      file = Image.open(f)\n",
        "      response = model.generate_content([summary_prompt, pytesseract.image_to_string(file)])\n",
        "\n",
        "    else:\n",
        "      file = genai.upload_file(f)\n",
        "\n",
        "      while file.state.name == \"PROCESSING\":\n",
        "        print(\"Waiting for video file upload...\\n\", end='')\n",
        "        time.sleep(5)\n",
        "        file = genai.get_file(file.name)\n",
        "\n",
        "      response = model.generate_content([summary_prompt, file])\n",
        "\n",
        "    files.append(file)\n",
        "    summaries.append(response.text)\n",
        "\n",
        "  return files, summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create a folder with all of our data of different modalities. In particular, the first 5 are audio files, next 3 are text files, and final 6 are video files."
      ],
      "metadata": {
        "id": "W9L-FAQz-UFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkwbUFxBWV-V"
      },
      "outputs": [],
      "source": [
        "all_files = []\n",
        "all_summaries = []\n",
        "\n",
        "for modality_type in [\"audio\", \"text\", \"video\"]:\n",
        "  files, summaries = create_summary(modality_type)\n",
        "  all_files.extend(files)\n",
        "  all_summaries.extend(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po7c72aFuHMt"
      },
      "outputs": [],
      "source": [
        "db = create_chroma_db(all_summaries, \"nasa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, ensure that the embeddings were generated. Notice that now, we have audio, video, and text data."
      ],
      "metadata": {
        "id": "iHvVQxOR96Gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6qkxWbWuHMt"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'embeddings': db.peek()['embeddings'],\n",
        "    'documents': db.peek()['documents']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame.from_dict(data, orient='index').transpose()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO7ANSetXBKH"
      },
      "outputs": [],
      "source": [
        "files = get_relevant_files(\"communication with Mission Control\", db)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can we do more than just return the most relevant file? Yes we can! We can ask Gemini to return a response to the query using the files it thinks are most relevant, provide an answer and tell us what files it used! This is really exciting, and has vast applications in many industries."
      ],
      "metadata": {
        "id": "vOSdVDCw-pgR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55Jd20kduHMt"
      },
      "outputs": [],
      "source": [
        "def query_rag(query, db):\n",
        "    files = get_relevant_files(query, db)\n",
        "    prompt = [all_files[int(f)] for f in files]\n",
        "    prompt.append(\"Generate a response to the query using the provided files. Here is the query.\")\n",
        "    prompt.append(query)\n",
        "    return model.generate_content(prompt).text, [all_file_names[int(f)] for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-gfX1LfuHMt"
      },
      "outputs": [],
      "source": [
        "for response in query_rag(\"Explain what happened with the Apollo 11 Mission.\", db):\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k02GjIuEuHMt"
      },
      "outputs": [],
      "source": [
        "for response in query_rag(\"What happens at the Translunar Coast in the Mission Description?\", db):\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats! You've built a full end to end multimodal RAG with just a few tools. We hope you enjoyed following along in this notebook and learned a lot on the way."
      ],
      "metadata": {
        "id": "k_wnqG1k-5W5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}